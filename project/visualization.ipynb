{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Importing Libraries and Defining Paths\n",
    "This cell imports essential libraries for the project and sets up configuration paths.\n",
    "\n",
    "### Libraries Imported:\n",
    "- `os`: For interacting with the operating system.\n",
    "- `numpy`: For numerical operations.\n",
    "- `pandas`: For data manipulation.\n",
    "- `rasterio`: For reading and writing geospatial raster data.\n",
    "- `subprocess`: For running subprocesses.\n",
    "\n",
    "### Paths:\n",
    "- Sets paths for training, validation, and testing datasets.\n",
    "- Sets paths for storing outputs and logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pathlib\n",
    "import math\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "from dataset import read_img\n",
    "from matplotlib import pyplot as plt\n",
    "import subprocess\n",
    "import pyperclip\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load configuration\n",
    "from config import config, update_config\n",
    "import argparse\n",
    "\n",
    "# Create a dummy namespace for arguments\n",
    "args = argparse.Namespace()\n",
    "\n",
    "# Update config with dummy arguments\n",
    "update_config(args)\n",
    "\n",
    "train_df = pd.read_csv(config['train_dir'])\n",
    "test_df = pd.read_csv(config['test_dir'])\n",
    "valid_df = pd.read_csv(config['valid_dir'])\n",
    "p_train_json = config['p_train_dir']\n",
    "p_test_json = config['p_test_dir']\n",
    "p_valid_json = config['p_valid_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Counting Images in Datasets\n",
    "This cell prints the total number of images in the training, testing, and validation datasets.\n",
    "\n",
    "### Outputs:\n",
    "- Total number of training images.\n",
    "- Total number of test images.\n",
    "- Total number of validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images = 46\n",
      "Total number of test images = 6\n",
      "Total number of validation images = 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of training images = {len(train_df)}\")\n",
    "print(f\"Total number of test images = {len(test_df)}\")\n",
    "print(f\"Total number of validation images = {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Checking Class Balance\n",
    "This cell defines a function to check the class percentage in the full dataset.\n",
    "\n",
    "### Function: `class_balance_check(patchify, data_dir)`\n",
    "- **Parameters**:\n",
    "  - `patchify` (bool): TRUE if class balance is to be checked for patchify experiments.\n",
    "  - `data_dir` (str): Directory where data files are saved.\n",
    "- **Returns**: Class percentage.\n",
    "- **Prints**:\n",
    "  - Class pixel percentage.\n",
    "  - Unique values in the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balance_check(patchify, data_dir):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        Checking class percentage in the full dataset\n",
    "    Arguments:\n",
    "        patchify (bool): TRUE if want to check class balance for patchify experiments\n",
    "        data_dir (str): directory where data files are saved \n",
    "    Return:\n",
    "        Class percentage\n",
    "    \"\"\"\n",
    "    if config['patchify']:\n",
    "        with open(config['p_train_dir'], \"r\") as j:\n",
    "            train_data = json.loads(j.read())\n",
    "        labels = train_data[\"masks\"]\n",
    "        patch_idx = train_data[\"patch_idx\"]\n",
    "    else:\n",
    "        train_data = pd.read_csv(config['train_dir'])\n",
    "        labels = train_data.masks.values\n",
    "        patch_idx = None\n",
    "\n",
    "    total = 0\n",
    "    class_name = {}\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        with rasterio.open(labels[i]) as msk:\n",
    "            mask = msk.read(1)\n",
    "\n",
    "        if config['patchify']:\n",
    "            idx = patch_idx[i]\n",
    "            mask = mask[idx[0] : idx[1], idx[2] : idx[3]]\n",
    "\n",
    "        total_pix = mask.shape[0] * mask.shape[1]\n",
    "        total += total_pix\n",
    "\n",
    "        dic = {}\n",
    "        keys = np.unique(mask)\n",
    "        for key in keys:\n",
    "            dic[key] = np.count_nonzero(mask == key)\n",
    "\n",
    "        for key, value in dic.items():\n",
    "            if key in class_name.keys():\n",
    "                class_name[key] = value + class_name[key]\n",
    "            else:\n",
    "                class_name[key] = value\n",
    "\n",
    "    for key, val in class_name.items():\n",
    "        class_name[key] = (val / total) * 100\n",
    "\n",
    "    print(\"Class percentage:\")\n",
    "    for key, val in class_name.items():\n",
    "        print(\"class pixel: {} = {}\".format(key, val))\n",
    "    print(f\"unique value in the mask {class_name.keys()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running Class Balance Check\n",
    "This cell runs the `class_balance_check` function on the dataset.\n",
    "\n",
    "### Outputs:\n",
    "- Class percentage for each class in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class percentage of training data before patch\n",
      "Class percentage:\n",
      "class pixel: 1.0 = 43.71723761925331\n",
      "class pixel: 2.0 = 56.282762380746696\n",
      "unique value in the mask dict_keys([1.0, 2.0])\n",
      ".........................................................................................\n",
      "Class percentage of training data after patch\n",
      "Class percentage:\n",
      "class pixel: 1.0 = 43.71723761925331\n",
      "class pixel: 2.0 = 56.282762380746696\n",
      "unique value in the mask dict_keys([1.0, 2.0])\n"
     ]
    }
   ],
   "source": [
    "print(\"Class percentage of training data before patch\")\n",
    "class_balance_check(patchify=False, data_dir=config['train_dir'])\n",
    "print(\".........................................................................................\")\n",
    "print(\"Class percentage of training data after patch\")\n",
    "class_balance_check(patchify=True, data_dir=config['p_train_dir'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Checking Unique Height and Width of Images\n",
    "This cell defines a function `check_height_width` to check and print unique heights and widths of images and masks in a dataset.\n",
    "\n",
    "### Function: `check_height_width(data_dir)`\n",
    "- **Parameters**: \n",
    "  - `data_dir` (str): Path to the CSV file.\n",
    "- **Process**:\n",
    "  - Reads the CSV file.\n",
    "  - Extracts image and mask paths.\n",
    "  - Iterates through the images and masks to find unique shapes.\n",
    "  - Prints the shapes of the dataset, input images, and masks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_height_width(data_dir):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        check unique hight and width of images from dataset\n",
    "    Arguments:\n",
    "        data_dir (str): path to csv file\n",
    "    Return:\n",
    "        print all the unique height and width\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv(data_dir)\n",
    "\n",
    "\n",
    "    print(\"Dataset:  \", data.shape)\n",
    "\n",
    "    input_img = data.feature_ids.values\n",
    "    input_mask = data.masks.values\n",
    "\n",
    "    input_img_shape = []\n",
    "    input_mask_shape = []\n",
    "\n",
    "    for i in range(len(input_img)):\n",
    "        with rasterio.open(input_img[i]) as im:\n",
    "            img = im.read()\n",
    "        with rasterio.open(input_mask[i]) as msk:\n",
    "            mask = msk.read()\n",
    "        # img = cv2.imread(input_img[i])\n",
    "        # mask = cv2.imread(input_mask[i])\n",
    "        print(f\"Shape for:{i} image Shape:{img.shape}    mask shape:{mask.shape}\")\n",
    "\n",
    "        if img.shape not in input_img_shape:\n",
    "            input_img_shape.append(img.shape)\n",
    "\n",
    "        if mask.shape not in input_mask_shape:\n",
    "            input_mask_shape.append(mask.shape)\n",
    "\n",
    "    print(\"Input image shapes: \", input_img_shape)\n",
    "    print(\"Input mask shapes: \", input_mask_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checking Image Dimensions in Different Datasets\n",
    "This cell prints the unique heights and widths of images and masks for training, testing, and validation datasets by calling the `check_height_width` function.\n",
    "\n",
    "### Actions:\n",
    "- Checks and prints unique image and mask dimensions for the training dataset.\n",
    "- Checks and prints unique image and mask dimensions for the testing dataset.\n",
    "- Checks and prints unique image and mask dimensions for the validation dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique height and width of training dataset\n",
      "Dataset:   (46, 2)\n",
      "Shape for:0 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:1 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:2 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:3 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:4 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:5 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:6 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:7 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:8 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:9 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:10 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:11 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:12 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:13 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:14 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:15 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:16 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:17 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:18 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:19 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:20 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:21 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:22 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:23 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:24 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:25 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:26 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:27 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:28 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:29 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:30 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:31 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:32 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:33 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:34 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:35 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:36 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:37 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:38 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:39 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:40 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:41 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:42 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:43 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:44 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:45 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Input image shapes:  [(3, 2048, 2048)]\n",
      "Input mask shapes:  [(1, 2048, 2048)]\n",
      ".........................................................................................\n",
      "Unique height and width of testing dataset\n",
      "Dataset:   (6, 2)\n",
      "Shape for:0 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:1 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:2 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:3 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:4 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:5 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Input image shapes:  [(3, 2048, 2048)]\n",
      "Input mask shapes:  [(1, 2048, 2048)]\n",
      ".........................................................................................\n",
      "Unique height and width of validation dataset\n",
      "Dataset:   (6, 2)\n",
      "Shape for:0 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:1 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:2 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:3 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:4 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Shape for:5 image Shape:(3, 2048, 2048)    mask shape:(1, 2048, 2048)\n",
      "Input image shapes:  [(3, 2048, 2048)]\n",
      "Input mask shapes:  [(1, 2048, 2048)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique height and width of training dataset\")\n",
    "check_height_width(config['train_dir'])\n",
    "print(\".........................................................................................\")\n",
    "print(\"Unique height and width of testing dataset\")\n",
    "check_height_width(config['test_dir'])\n",
    "print(\".........................................................................................\")\n",
    "print(\"Unique height and width of validation dataset\")\n",
    "check_height_width(config['valid_dir'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plotting Metrics from CSV Files\n",
    "This cell defines functions to handle CSV files and plot metrics against epochs.\n",
    "\n",
    "### Functions:\n",
    "- `return_csv_from_path`: Returns a list of CSV file paths from a directory.\n",
    "- `_plot_from_csv`: Plots specified columns from a CSV file against epochs.\n",
    "- `plot_metrics_vs_epochs`: Plots metrics from a CSV file against epochs using `_plot_from_csv`.\n",
    "- `plot_metric_vs_epochs_vs_models`: Plots a specific metric against epochs for different models and saves the combined results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_csv_from_path(csv_path=config['csv_logger_path']):\n",
    "    csv_list = []\n",
    "    # Iterate through each subdirectory\n",
    "    for folder in csv_path.iterdir():\n",
    "        # Check if the entry is a directory\n",
    "        if folder.is_dir():\n",
    "            # Iterate through files in the subdirectory\n",
    "            for file in folder.iterdir():\n",
    "                # Check if the entry is a file\n",
    "                if file.is_file():\n",
    "                    csv_list.append(file)\n",
    "    return csv_list\n",
    "\n",
    "def _plot_from_csv(csv_path, name, x_axis_name, y_axis_name, columns_to_plot=None):\n",
    "    pathlib.Path((config['root_dir'] / \"logs\" / \"plots\" / \"metrics_plots\")).mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    epochs = df['epoch']\n",
    "    if columns_to_plot is not None:\n",
    "        columns_to_plot = columns_to_plot\n",
    "    else:\n",
    "        columns_to_plot = df.columns.to_list()[1:]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for column in columns_to_plot:\n",
    "        plt.plot(epochs, df[column], label=column, linewidth=3.0, marker=\"o\", markersize=5)\n",
    "\n",
    "    plt.title(f\"{y_axis_name}_over_{x_axis_name}\")\n",
    "    plt.xlabel(x_axis_name)\n",
    "    plt.ylabel(y_axis_name)\n",
    "    plt.xticks(epochs.astype(int))\n",
    "    plt.legend()\n",
    "    plt.savefig(config['root_dir'] / \"logs\" / \"plots\" / \"metrics_plots\" / name)\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics_vs_epochs(csv_path, name, x_axis_name=\"Epochs\", y_axis_name=\"Metrics_score\", columns_to_plot=None):\n",
    "    _plot_from_csv(csv_path=csv_path, name=name, x_axis_name=x_axis_name, y_axis_name=y_axis_name, columns_to_plot=columns_to_plot)\n",
    "\n",
    "def plot_metric_vs_epochs_vs_models(metric_name=\"my_mean_iou\"):\n",
    "    pathlib.Path((config['root_dir'] / \"logs\" / \"plots\" / \"csv_for_plotting\")).mkdir(parents=True, exist_ok=True)\n",
    "    csv_list = return_csv_from_path()\n",
    "    result_df = pd.DataFrame()\n",
    "    for csv_path in csv_list:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        result_df[os.path.basename(csv_path)] = df[metric_name]\n",
    "    result_df.index.name = \"epoch\"\n",
    "    result_df.to_csv(os.path.join(config['root_dir'] / \"logs\" / \"plots\" / \"csv_for_plotting\" / f\"{metric_name}_vs_epoch.csv\"), encoding='utf-8', index=True, header=True)\n",
    "    _plot_from_csv(config['root_dir'] / \"logs\" / \"plots\" / \"csv_for_plotting\" / f\"{metric_name}_vs_epoch.csv\", x_axis_name=\"Epochs\", y_axis_name=metric_name, name=metric_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plotting Specific Metrics from CSV Files\n",
    "This cell plots metrics against epochs using previously defined functions.\n",
    "\n",
    "### Actions:\n",
    "- Plots metrics from a specified CSV file.\n",
    "- Plots F1 score from a specified CSV file.\n",
    "- Plots metrics for different models.\n",
    "- Plots recall metric for different models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_vs_epochs(config['csv_logger_path'] / \"planet-2\" / \"planet-2_ex_2024-07-13_e_4000_p_2048_s_1024_nsr-1_dtype_nsr-1.csv\", name='metrics')\n",
    "plot_metrics_vs_epochs(config['csv_logger_path'] / \"planet-2\" / \"planet-2_ex_2024-07-13_e_4000_p_2048_s_1024_nsr-1_dtype_nsr-1.csv\", name='metrics', columns_to_plot=[\"my_mean_iou\"])\n",
    "plot_metric_vs_epochs_vs_models()\n",
    "plot_metric_vs_epochs_vs_models(metric_name=\"my_mean_iou\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Percentage Clipping Function\n",
    "Defines `pct_clip` to clip array values between specified percentiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_clip(array, pct=[2.5, 97.5]):\n",
    "    array_min, array_max = np.nanpercentile(array, pct[0]), np.nanpercentile(array, pct[1])\n",
    "    clip = (array - array_min) / (array_max - array_min)\n",
    "    clip[clip > 1] = 1\n",
    "    clip[clip < 0] = 0\n",
    "    return clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rio.open(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/dataset/input/tile_0_0_vVvHdF_Area1_17-18_Beg.tif\") as src:\n",
    "#     with rio.open(\n",
    "#             'RGB_Temp.tif', 'w+',\n",
    "#             driver='GTiff',\n",
    "#             dtype= rio.float32,\n",
    "#             count=3,\n",
    "#             crs = src.crs,\n",
    "#             width=src.width,\n",
    "#             height=src.height,\n",
    "#             transform=src.transform,\n",
    "#         ) as dst:\n",
    "#         V = pct_clip(src.read(1))\n",
    "#         dst.write(V.astype(rio.float32),1)\n",
    "#         V = pct_clip(src.read(2))\n",
    "#         dst.write(V.astype(rio.float32),2)\n",
    "#         V = pct_clip(src.read(3))\n",
    "#         dst.write(V.astype(rio.float32),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rio.open(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/dataset/input/tile_0_0_vVvHdF_Area1_17-18_Beg.tif\") as src:\n",
    "#     # img= np.zeros((3,512,512))\n",
    "#     img= pct_clip(src.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. False Color Image Reading Function\n",
    "Defines `false_colour_read` to read an image and apply percentage clipping to each channel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_colour_read(path):\n",
    "    img= np.zeros((3,512,512))\n",
    "    with rasterio.open(path) as src:\n",
    "        for i in range(3):\n",
    "            img[i,:,:]= pct_clip(src.read(i+1))\n",
    "            \n",
    "    return img, src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "global h,w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. False Color Image Reading Function with Dynamic Shape\n",
    "Defines `false_colour_read_bt` to read an image with dynamic shape and apply percentage clipping to each channel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_colour_read_bt(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        global h,w\n",
    "        h,w =src.shape\n",
    "        img= np.zeros((3,h,w))\n",
    "        # print(img.shape)\n",
    "        for i in range(3):\n",
    "            img[i,:,:]= pct_clip(src.read(i+1))\n",
    "            \n",
    "    return img, src\n",
    "# print(\"displaying training images and masks\")\n",
    "# display_all(data=train_df,name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3024826/3490577295.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "np.zeros((h,w,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots()\n",
    "# with rio.open(\"RGB_Temp.tif\") as src2:\n",
    "#     show(src2.read(),transform=src2.transform,ax=ax)\n",
    "#     ax.grid(False)  # Turn off gridlines along the borders\n",
    "#     ax.set_xticks([])  # Remove x-axis ticks\n",
    "#     ax.set_yticks([])  # Remove y-axis ticks\n",
    "#     ax.set_xlabel('')  # Remove x-axis label\n",
    "#     ax.set_ylabel('')  # Remove y-axis label\n",
    "# plt.show()\n",
    "# plt.savefig(\"false_color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_dir = config[\"root_dir\"] / \"data/nsr-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Displaying and Saving All Images and Masks\n",
    "Defines `display_all` to save images and their corresponding masks into a single figure for visualization.\n",
    "\n",
    "### Function: `display_all(data, name)`\n",
    "- **Parameters**:\n",
    "  - `data`: Data file holding image paths.\n",
    "  - `name` (str): Path to save images.\n",
    "- **Process**:\n",
    "  - Reads and processes each image and mask.\n",
    "  - Displays images and masks in a figure.\n",
    "  - Saves the figure to the specified directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(data, name):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        save all images into single figure\n",
    "    Arguments:\n",
    "        data : data file holding images path\n",
    "        directory (str) : path to save images\n",
    "    Return:\n",
    "        save images figure into directory\n",
    "    \"\"\"\n",
    "\n",
    "    pathlib.Path((visualization_dir / \"display\")).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path((visualization_dir / \"display\"/\"train\")).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path((visualization_dir / \"display\"/\"test\")).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path((visualization_dir / \"display\"/\"valid\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        image,src = false_colour_read_bt(data.feature_ids.values[i])\n",
    "        print(image.shape)\n",
    "        print(np.mean(image),np.std(image))\n",
    "        mask = read_img(data.masks.values[i], label=True)\n",
    "        print(\"................................\")\n",
    "        print(f\"image_shape: {image.shape}\")\n",
    "        print(f\"mask_shape: {mask.shape}\")\n",
    "        print(\"................................\")\n",
    "        id = data.feature_ids.values[i].split(\"/\")[-1]\n",
    "        display_list = {\"image\": image, \"label\": mask}\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        title = list(display_list.keys())\n",
    "\n",
    "        for i in range(len(display_list)):\n",
    "            plt.subplot(1, len(display_list), i + 1)\n",
    "            plt.title(title[i])\n",
    "            if title[i]=='image':\n",
    "                ax = plt.gca()\n",
    "                show(display_list[title[i]],transform=src.transform, ax=ax)\n",
    "            else:\n",
    "                plt.imshow((display_list[title[i]]), cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        prediction_name = \"img_id_{}.png\".format(id)  # create file name to save\n",
    "        plt.savefig(\n",
    "            os.path.join((visualization_dir / \"display\"/ name), prediction_name),\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=800,\n",
    "        )\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Loading Dataset CSV Files\n",
    "Loads training, testing, and validation datasets from CSV files.\n",
    "\n",
    "### Actions:\n",
    "- Reads the training dataset CSV file.\n",
    "- Reads the testing dataset CSV file.\n",
    "- Reads the validation dataset CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/nsr-1/data/csv/train.csv\")\n",
    "test_df =  pd.read_csv(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/nsr-1/data/csv/test.csv\")\n",
    "valid_df = pd.read_csv(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/nsr-1/data/csv/valid.csv\")\n",
    "# p_train_json = config.p_train_dir\n",
    "# p_test_json = config.p_test_dir\n",
    "# p_valid_json = config.p_valid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from config import *\n",
    "import config\n",
    "import tensorflow as tf\n",
    "# from logging import config\n",
    "from einops import rearrange\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import keras_unet_collection.models as kuc\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LeakyReLU, add, Conv2D, PReLU, ReLU, Concatenate, Activation, MaxPool2D, Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Reading and Normalizing Images and Masks\n",
    "Defines `read_img` to read and normalize images and masks using `rasterio`.\n",
    "\n",
    "### Function: `read_img(directory, in_channels=None, label=False, patch_idx=None, height=256, width=256)`\n",
    "- **Parameters**:\n",
    "  - `directory` (str): Path to the image.\n",
    "  - `in_channels` (bool, optional): Number of channels to read.\n",
    "  - `label` (bool): True if reading a mask, otherwise False.\n",
    "  - `patch_idx` (list, optional): Patch indices to read.\n",
    "  - `height` (int, optional): Height of the image.\n",
    "  - `width` (int, optional): Width of the image.\n",
    "- **Returns**: Numpy array of the image or mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(directory, in_channels=None, label=False, patch_idx=None, height=256, width=256):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "        read image with rasterio and normalize the feature\n",
    "    Arguments:\n",
    "        directory (str): image path to read\n",
    "        in_channels (bool): number of channels to read\n",
    "        label (bool): TRUE if the given directory is mask directory otherwise False\n",
    "        patch_idx (list): patch indices to read\n",
    "    Return:\n",
    "        numpy.array\n",
    "    \"\"\"\n",
    "\n",
    "    # for musk images\n",
    "    if label:\n",
    "        with rasterio.open(directory) as fmask: # opening the directory\n",
    "            mask = fmask.read(1)    # read the image (Data from a raster band can be accessed by the band’s index number. Following the GDAL convention, bands are indexed from 1. [int or list, optional] – If indexes is a list, the result is a 3D array, but is a 2D array if it is a band index number.\n",
    "        \n",
    "        mask[mask == 2.0] = 0\n",
    "        mask[mask == 1.0] = 1\n",
    "        # np.swapaxes(mask,0,2)\n",
    "        # mask[mask == 255] = 1\n",
    "        mask[mask == 170] = 2\n",
    "        # mask[mask == 85] = 2\n",
    "        mask = mask[... , np.newaxis]\n",
    "        mask = mask.astype(\"int32\")\n",
    "        # print(\".......mask...............\")\n",
    "        # print(mask.shape)\n",
    "    \n",
    "        if patch_idx:\n",
    "            # extract patch from original mask\n",
    "            return mask[patch_idx[0]:patch_idx[1], patch_idx[2]:patch_idx[3]]\n",
    "        else:\n",
    "            return mask #np.expand_dims(mask, axis=2)\n",
    "    # for features images\n",
    "    else:\n",
    "        # read N number of channels\n",
    "        with rasterio.open(directory) as inp:\n",
    "            X =inp.read()\n",
    "        X= np.swapaxes(X,0,2)\n",
    "        X = (X-config[\"mean\"])/config[\"std\"]\n",
    "        if patch_idx:\n",
    "            # extract patch from original features\n",
    "            return X[patch_idx[0]:patch_idx[1], patch_idx[2]:patch_idx[3], :]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Displaying Training Images and Masks\n",
    "Displays and saves training images and masks using the `display_all` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying training images and masks\n",
      "(3, 2048, 2048)\n",
      "0.45905334162016237 0.26210658493878514\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4231295877359089 0.30436063065924696\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.49032868802117285 0.2732168338553924\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.43081603305717414 0.2726879906249073\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.44685053335421526 0.27884300356909714\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45334690877176853 0.26362800146950405\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.5021271530055498 0.25958793451276135\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.48633221683999506 0.2942989795089574\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4562835426695579 0.2615703345899844\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4426936295507054 0.29522997833094666\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.42804271064116134 0.2650627424637966\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.46808287032972196 0.26013434943514346\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.1747886644850903 0.2866236137097558\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.43220034116797407 0.27172967545463267\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.44611564409413224 0.2767481216997337\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.47537669129053334 0.27101527883126075\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4736129815162243 0.2842662717517389\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4373305167781207 0.27529226423978986\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45179923482844425 0.2686139556576539\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.41299239437434915 0.30847330634315356\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.44433374667963554 0.255400593369021\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.19362495936922708 0.2802363019227737\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4396778434291957 0.2697326775505481\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.43981000108291907 0.26203314618828316\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.44534816700827934 0.2580590342918061\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45044383057021675 0.27177297731856603\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4546625103840183 0.2639383101949453\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4588764085894168 0.2588112262763582\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45385190968699285 0.27618713437705394\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4267335821479498 0.2757619724506848\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.43721843033536406 0.2746973307589788\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45209702784357764 0.26616060468901\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45020771186469055 0.2692072306503239\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4930265497868771 0.2575801807066175\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.43611466741845767 0.26574789350760836\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.44859064253902337 0.2718247340902277\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4193664942675461 0.26288996840958717\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45338600015597136 0.27016568410601477\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45011919045653553 0.26123199548907666\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.41826566280638366 0.2682176288035901\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.40247618723446027 0.2786365486164636\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4381153612896405 0.27153267965921746\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4420094192607182 0.27556807353626867\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.42969291395954023 0.300629998339311\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.45470292937298296 0.26336360283927757\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4372982686033579 0.26611284936401014\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n"
     ]
    }
   ],
   "source": [
    "print(\"displaying training images and masks\")\n",
    "display_all(data=train_df,name=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Displaying Testing Images and Masks\n",
    "Displays and saves testing images and masks using the `display_all` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying testing images and masks\n",
      "(3, 2048, 2048)\n",
      "0.4614242265964597 0.25907621930535063\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.5096356904234135 0.27964891278188814\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.43287478030391396 0.264148527395466\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.44688856108519 0.2918150079265977\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.41630318034187214 0.3078911617133381\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.406943987636486 0.30234890239838397\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n"
     ]
    }
   ],
   "source": [
    "print(\"displaying testing images and masks\")\n",
    "display_all(data=test_df, name = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Displaying Validation Images and Masks\n",
    "Displays and saves validation images and masks using the `display_all` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying validation images and masks\n",
      "(3, 2048, 2048)\n",
      "0.4810193831846115 0.2649052017633632\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.404305705893939 0.28803888926824484\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4863573461569 0.26044502706106587\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.43049160725798563 0.2655540340256653\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.421098497233139 0.26795243400117935\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n",
      "(3, 2048, 2048)\n",
      "0.4073432169947597 0.3067610144743087\n",
      "................................\n",
      "image_shape: (3, 2048, 2048)\n",
      "mask_shape: (2048, 2048, 1)\n",
      "................................\n"
     ]
    }
   ],
   "source": [
    "print(\"displaying validation images and masks\")\n",
    "display_all(data=valid_df, name= \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Calculating Statistics for Image Bands\n",
    "Loads training dataset CSV and defines a function to calculate mean and standard deviation for each band of the images.\n",
    "\n",
    "### Actions:\n",
    "- Loads training dataset CSV.\n",
    "- Defines `calculate_stats` to:\n",
    "  - Read and clip the first three bands of each image.\n",
    "  - Calculate and print the mean and standard deviation for each band.\n",
    "- Calls `calculate_stats` with the list of feature image paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mean across 1st band: 0.4691332033859703\n",
      "Standard deviation across 1st band: 0.28278651995773896\n",
      "Average mean across 2bd band: 0.46229958486139205\n",
      "Standard deviation across 2nd band: 0.26957449339570383\n",
      "Average mean across 3rd band: 0.37691639220534906\n",
      "Standard deviation across 3rd band: 0.27380976043702177\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation2/data/nsr-1/data/csv/train.csv\")\n",
    "features_path = train_df[\"feature_ids\"].to_list()\n",
    "def calculate_stats(file_paths):\n",
    "    all_data1 = []\n",
    "    all_data2 = []\n",
    "    all_data3 = []\n",
    "    for file_path in file_paths:\n",
    "        with rasterio.open(file_path) as src:\n",
    "            data1 = pct_clip(src.read(1))  # Read the first band\n",
    "            all_data1.append(data1)\n",
    "            data2 = pct_clip(src.read(2))  # Read the first band\n",
    "            all_data2.append(data2)\n",
    "            data3 = pct_clip(src.read(3))  # Read the first band\n",
    "            all_data3.append(data3)\n",
    "\n",
    "    # Stack all the data into a single numpy array\n",
    "    stacked_data1 = np.stack(all_data1)\n",
    "    stacked_data2 = np.stack(all_data2)\n",
    "    stacked_data3 = np.stack(all_data3)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean1 = np.mean(stacked_data1)\n",
    "    std_dev1 = np.std(stacked_data1)\n",
    "    mean2 = np.mean(stacked_data2)\n",
    "    std_dev2 = np.std(stacked_data2)\n",
    "    mean3 = np.mean(stacked_data3)\n",
    "    std_dev3 = np.std(stacked_data3)\n",
    "    print(\"Average mean across 1st band:\", mean1)\n",
    "    print(\"Standard deviation across 1st band:\", std_dev1)\n",
    "    print(\"Average mean across 2bd band:\", mean2)\n",
    "    print(\"Standard deviation across 2nd band:\", std_dev2)\n",
    "    print(\"Average mean across 3rd band:\", mean3)\n",
    "    print(\"Standard deviation across 3rd band:\", std_dev3)\n",
    "\n",
    "# Example list of file paths\n",
    "calculate_stats(features_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Calculating Overall Statistics for All Image Bands\n",
    "Loads training dataset CSV and defines a function to calculate mean and standard deviation for all bands of the images.\n",
    "\n",
    "### Actions:\n",
    "- Loads training dataset CSV.\n",
    "- Defines `calculate_stats` to:\n",
    "  - Read and clip all bands of each image.\n",
    "  - Calculate and return the mean and standard deviation for all bands combined.\n",
    "- Calls `calculate_stats` with the list of feature image paths.\n",
    "- Prints the average mean and standard deviation across all files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average mean across all files: 0.409134915248531\n",
      "Standard deviation across all files: 0.2813810486906851\n"
     ]
    }
   ],
   "source": [
    "# /mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/dataset-nsr-3/data/csv\n",
    "train_df = pd.read_csv(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation2/data/nsr-1/data/csv/train.csv\")\n",
    "features_path = train_df[\"feature_ids\"].to_list()\n",
    "def calculate_stats(file_paths):\n",
    "    all_data = []\n",
    "    for file_path in file_paths:\n",
    "        with rasterio.open(file_path) as src:\n",
    "            data = pct_clip(src.read()) \n",
    "            # print(data.shape)\n",
    "            all_data.append(data)\n",
    "\n",
    "    # Stack all the data into a single numpy array\n",
    "    stacked_data = np.stack(all_data)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = np.mean(stacked_data)\n",
    "    std_dev = np.std(stacked_data)\n",
    "\n",
    "    return mean, std_dev\n",
    "\n",
    "# Example list of file paths\n",
    "\n",
    "mean, std_dev = calculate_stats(features_path)\n",
    "\n",
    "print(\"Average mean across all files:\", mean)\n",
    "print(\"Standard deviation across all files:\", std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Saving Image Tiles\n",
    "Defines `save_tiles` to split large images into smaller tiles and save them.\n",
    "\n",
    "### Function: `save_tiles(path, out_path, tiles_size=2048, stride=1024)`\n",
    "- **Parameters**:\n",
    "  - `path`: Directory with original images.\n",
    "  - `out_path`: Directory to save the tiles.\n",
    "  - `tiles_size`: Size of each tile.\n",
    "  - `stride`: Stride for tiling.\n",
    "- **Process**: Iterates through images, splits them into tiles, and saves the tiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tiles(path, out_path, tiles_size=2048, stride=1024):\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    \n",
    "    # Iterate over each file in the path\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        with rasterio.open(file_path) as src:\n",
    "            # Get metadata and calculate number of tiles in each dimension\n",
    "            meta = src.meta\n",
    "            meta[\"height\"]= tiles_size\n",
    "            meta[\"width\"]= tiles_size\n",
    "            # print(meta)\n",
    "            height, width = src.shape\n",
    "            num_rows = math.ceil((height - tiles_size) / stride + 1)\n",
    "            num_cols = math.ceil((width - tiles_size) / stride + 1)\n",
    "            total_tiles = num_rows* num_cols\n",
    "            print(f\"shape of the image before tiles : {src.shape}\")\n",
    "            print(f\"number of tiles={total_tiles}\")\n",
    "            print(\"..................................................\")\n",
    "            # Iterate over each tile\n",
    "            for row in range(num_rows):\n",
    "                for col in range(num_cols):\n",
    "                    # Calculate window coordinates\n",
    "                    row_start = row * stride\n",
    "                    row_stop = min(row_start + tiles_size, height)\n",
    "                    col_start = col * stride\n",
    "                    col_stop = min(col_start + tiles_size, width)\n",
    "                    \n",
    "                    # Read the tile data\n",
    "                    # window = Window(x0, y0, x1 - x0, y1 - y0)\n",
    "                    window = Window.from_slices((row_stop-stride, row_stop), (col_stop-stride, col_stop))\n",
    "                    tile_data = src.read(window=window)\n",
    "                    # print(\"...........\")\n",
    "                    # print(tile_data.shape)\n",
    "                    # Save the tile with a suffix of tile id\n",
    "                    # out_filename = f\"{os.path.splitext(filename)[0]}_tile_{row}_{col}.tif\"\n",
    "                    out_filename = f\"tile_{row}_{col}_{os.path.splitext(filename)[0]}.tif\"\n",
    "                    out_file_path = os.path.join(out_path, out_filename)\n",
    "                    with rasterio.open(out_file_path, 'w', **meta) as dst:\n",
    "                        dst.write(tile_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Data Path\n",
    "Sets the data path for the input images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/nsr-1/input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Output Path\n",
    "Sets the output path for saving the image tiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=\"/mnt/hdd2/mdsamiul/project/rice_crop_segmentation/data/nsr-1/input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Execute Image Tiling\n",
    "Calls the `save_tiles` function to split images into tiles and save them to the specified output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n",
      "shape of the image before tiles : (2048, 2048)\n",
      "number of tiles=1\n",
      "..................................................\n"
     ]
    }
   ],
   "source": [
    "save_tiles(data,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Renaming Files\n",
    "Defines `rename_files` to rename files in the specified directory based on predefined patterns.\n",
    "\n",
    "### Function: `rename_files(datapath)`\n",
    "- **Parameters**:\n",
    "  - `datapath`: Directory containing the files to rename.\n",
    "- **Process**:\n",
    "  - Lists all files in the directory.\n",
    "  - Renames files based on specific prefixes (`DEM_`, `VV_`, `VH_`, `GT_`).\n",
    "  - Constructs new file paths and renames the files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(datapath):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(datapath)\n",
    "    \n",
    "    for filename in files:\n",
    "        # Extract the file extension\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        \n",
    "        # Check if the filename starts with DEM_ab.tif\n",
    "        if filename.startswith(\"DEM_\"):\n",
    "            new_filename = filename.replace(\"DEM_\", \"\").replace(\".tif\", \"_nasadem.tif\")\n",
    "        \n",
    "        # Check if the filename starts with VV_ab.tif\n",
    "        elif filename.startswith(\"VV_\"):\n",
    "            new_filename = filename.replace(\"VV_\", \"\").replace(\".tif\", \"_vv.tif\")\n",
    "        \n",
    "        # Check if the filename starts with VH_ab.tif\n",
    "        elif filename.startswith(\"VH_\"):\n",
    "            new_filename = filename.replace(\"VH_\", \"\").replace(\".tif\", \"_vh.tif\")\n",
    "        \n",
    "        # Check if the filename starts with GT_ab.tif\n",
    "        elif filename.startswith(\"GT_\"):\n",
    "            new_filename = filename.replace(\"GT_\", \"\")\n",
    "        \n",
    "        else:\n",
    "            # If none of the conditions are met, skip this file\n",
    "            raise ValueError(\"files_name_mismatch\")\n",
    "        \n",
    "        # Construct the new filepath\n",
    "        new_filepath = os.path.join(datapath, new_filename)\n",
    "        \n",
    "        # Rename the file\n",
    "        os.rename(os.path.join(datapath, filename), new_filepath)\n",
    "        print(f\"Renamed {filename} to {new_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. Execute File Renaming\n",
    "Calls the `rename_files` function to rename files in the specified dataset directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = config.dataset_dir\n",
    "rename_files(datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. Running Visualization Script and Saving Output\n",
    "Runs a visualization script and saves the terminal output to an RTF file.\n",
    "\n",
    "### Actions:\n",
    "- Executes the `visualization.py` script using a terminal command.\n",
    "- Captures the terminal output.\n",
    "- Saves the output to `data_statistics.rtf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal output saved to data_statistics.rtf\n"
     ]
    }
   ],
   "source": [
    "# Run the command in the terminal\n",
    "command = \"python visualization.py\"\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Get the terminal output\n",
    "terminal_output = result.stdout\n",
    "\n",
    "# Save the output to an RTF file\n",
    "rtf_filename = \"data_statistics.rtf\"\n",
    "with open(rtf_filename, \"w\") as rtf_file:\n",
    "    # rtf_file.write(\"{\\\\rtf1\\\\ansi\\n\")\n",
    "    rtf_file.write(terminal_output)\n",
    "    # rtf_file.write(\"}\")\n",
    "\n",
    "print(f\"Terminal output saved to {rtf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
